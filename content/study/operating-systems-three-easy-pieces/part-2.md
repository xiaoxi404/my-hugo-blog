---
title: "Cpu Virtualization Part 2"
date: 2022-05-04T16:26:57+08:00
draft: false
slug: cpu-virtualization-2
---

# 第6章 机制：受限直接执行

通过时分共享（time sharing）CPU的方式，来实现CPU虚拟化，即：运行一个进程一段时间，然后运行另一个进程，如此轮换。

时分共享的挑战：性能和控制权。

## 6.1 基本技巧：受限直接执行

<center> 直接运行协议（无限制） </center>

| 操作系统 | 程序 |
| :-- | :-- |
| 在进程列表上创建条目<br>为程序分配内存<br>将程序加载到内存中<br>根据 argc/argv 设置程序栈 |  |
| 清楚寄存器<br>执行call main() |  |
| | 执行main()<br>从main中执行return |
| 释放进程的内存<br>从进程列表中清除 | |

## 6.2 问题一：受限制的操作

为了让用户执行一些受限操作，引入一种新的处理器模式，称为用户模式（user mode）。在用户模式下运行的代码会受到限制。

与用户模式不同的内核模式（kernel mode），操作系统（或内核）就以这种模式运行。在此模式下，运行的代码可以做任何事，包括特权操作。

如果用户希望执行特权操作，用户需要使用执行系统调用。

系统调用允许内核小心地向用户程序暴露某些关键功能，例如访问文件系统，创建和销毁进程，与其他进程通信，以及分配更多内存。

要执行系统调用，程序必须执行陷阱（trap）指令。该指令同时跳入内核并将特权级别提升到内核模式。一旦进入内核，系统就可以执行任何需要的特权操作（如果允许），从而为调用进程执行所需的工作。完成后，操作系统调用一个特殊的从陷阱返回（return-from-trap）指令，该指令返回到发起调用的用户程序中，同时将特权级别降低，回到用户模式。

内核如何控制在陷阱上执行的代码？内核通过在启动时设置陷阱表（trap table）。

我们假设每一个进程都有一个内核栈，在进入内核和离开内核时需要将reg和pc保存和恢复。

<center> 受限直接运行协议（系统启动时） </center>

| 操作系统@启动(kernel mode) | 硬件|
| :-- | :-- |
| 初始化陷阱表 | |
| |记住系统调用处理程序的地址 |


<center> 受限直接运行协议（系统运行时） </center>

| 操作系统@运行（kernel mode） | 硬件 | 程序（user mode） |
| :-- | :-- | :-- |
| 在进程列表创建条目<br> 为进程分配内存<br> 将进程加载到内存中<br> 根据argv设置程序栈<br> 用reg/pc填充内核栈 |  |  |
| | 从内核栈恢复reg<br> 转到user mode<br> 跳到main | |
| | | 运行main<br> ...... <br> 调用系统调用<br> 陷入操作系统 |
| | 将reg保存到内核栈<br> 转到kernel mode<br> 跳到陷阱处理程序 | |
|处理陷阱<br> 做系统调用的工作<br> 从陷阱返回 | | |
| | 从内核栈恢复reg<br> 转到user mode<br> 转到陷阱之后的PC ||
| | | ......<br> 从main返回<br> 陷入<通过exit()> |
| 释放进程的内存<br> 将进程从进程列表清除 | | |

## 6.3 问题二：在进程间切换

### 协作方式：等待系统调用

系统信任程序会合理运行，如果程序执行了非法操作，会陷入（trap）系统，系统再次控制cpu。

### 非协作方式：操作系统进行控制

利用时钟中断（timer interrupt），时钟设备可以编程为每隔几毫秒产生一次中断。产生中断时，当前正在运行的进程停止，操作系统中预先配置的中断处理程序（interrupt handler）会运行。此时，操作系统重新获得 CPU 的控制权。

### 保存和恢复上下文

系统切换进程，OS会执行一些代码（即所谓的上下文切换（context switch））。

上下文切换：OS为当前正在执行的进程保存一些寄存器的值（例如，到它的内核栈），并为即将执行的进程恢复一些寄存器的值（从它的内核栈）。

<center> 受限直接运行协议（系统启动时） </center>

| 操作系统@启动（kernel mode） | 硬件 |
| :--| :-- |
| 初始化陷阱表 | |
| | 记住系统调用处理程序和时钟中断处理程序地址 |
| 启动系统时钟 | |
| | 启动时钟<br> 每隔 x ms中断CPU |

<center> 受限直接运行协议（系统运行时） </center>

| 操作系统@运行（kernel mode） | 硬件 | 程序（user mode） |
| :-- | :-- | :-- |
| | | 进程A...... |
| | 时钟中断<br> 将reg（A）保存到内核栈（A）<br> 转到内核模式<br> 跳到陷阱处理程序 | |
|处理陷阱<br> 调用switch()例程<br> 将寄存器（A）保存到进程结构（A）<br> 将进程结构（B）恢复到寄存器（B）<br> 从陷阱返回（进入B）  | | |
| | 从内核栈（B）恢复到reg（B）<br> 转到user mode<br> 跳到B的程序计数器 | |
| | | 进程B...... |

## 6.4 担心并发吗？

本书并发部分讨论。

## 6.5 小结

OS在启动时设置陷阱处理程序并启动时钟中断，然后在受限模式下运行进程，以此为CPU提供“保护”。这样做，操作系统能确信进程可以高效运行。只在执行特权操作，或者当它们独占CPU时间过长并因此需要切换时，才需要操作系统干预。

# 第7章 进程调度：介绍

## 7.1 工作负载假设

略

## 7.2 调度指标

1. 周转时间（turnaround time）：`$ T_{周转时间} = T_{完成时间} - T_{到达时间} $`

2. 公平（fairness）

## 7.3 先进先出（FIFO）

先进先出服务，又称先到先服务（First Come First Served 或 FCFS）。

![FIFO](https://img.nobody404.xyz/img/FIFO.webp)

护航效应（convoy effect），一些耗时较少的潜在资源消费者被排在重量级的资源消费者之后。

## 7.4 最短任务优先（SJF）

最短任务优先（Shorted Job First，SJF）。

![SJF](https://img.nobody404.xyz/img/SJF.webp)

## 7.5 最短完成时间优先（STCF）

STCF：向 SJF 添加抢占，称为最短完成时间优先（Shortest Time-to-Completion First，STCF）或抢占式最短作业优先（Preemptive Shortest Job First ，PSJF）。每当新工作进入系统时，它就会确定剩余工作和新工作中，谁的剩余时间最少，然后调度该工作。

![STCF](https://img.nobody404.xyz/img/STCF.webp)

## 7.6 新度量指标：响应时间

响应时间：`$ T_{响应时间} = T_{首次运行时间} - T_{到达时间} $`

## 7.7 轮转

轮转（Round-RObin，RR）：RR 在一个时间片（time slice，有时称为调度量子，scheduling quantum，其长度必须是时钟中断周期的倍数）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。它反复执行，直到所有任务完成。

![RR](https://img.nobody404.xyz/img/RR.webp)

突然上下文切换的成本将影响整体性能。因此，系统设计者需要权衡时间片的长度，使其足够长，以便摊销（amortize）上下文切换成本，而又不会使系统不及时响应。

## 7.8 结合I/O

如下图将A工作分割成小的子工作。

![schedule_with_IO](https://img.nobody404.xyz/img/schedule_with_IO.webp)

## 7.9 无法预知

实际上我们是无法预知工作的工作时间的。

## 7.10 小结

介绍了调度基本思想，介绍了两种方法。第一类是运行最短工作，从而优化周转时间。第二类是交替运行所有工作，从而优化响应时间。很难做到鱼和熊掌兼得。

# 第8章 调度：多级反馈队列

多级反馈队列（Multi-level Feedback Queue，MLFQ）优化了周转时间，降低了响应时间。

## 8.1 MLFQ：基本规则

MLFQ 中有许多独立的队列（queue），每个队列有不同的优先级（priority level）。任何时刻，一个工作只能存在于一个队列中。MLFQ 总是优先执行较高优先级的工作（即在较高级队列中的工作）。

当然，每个队列中可能会有多个工作，因此具有同样的优先级。在这种情况下，我们就对这些工作采用轮转调度。

总结：

- 规则1： 如果 A 的优先级 > B 的优先级，运行 A（不运行 B）。

- 规则2： 如果 A 的优先级 = B 的优先级，轮转运行 A 和 B。

![MLFQ-1](https://img.nobody404.xyz/img/MLFQ-1.webp)

## 8.2 尝试1：如何改变优先级

- 规则 3：工作进入系统时，放在最高优先级（最上层队列）。
- 规则 4a：工作用完整个时间片后，降低其优先级（移入下一个队列）。
- 规则 4b：如果工作在其时间片以内主动释放CPU，则优先级不变。

![MLFQ-2](https://img.nobody404.xyz/img/MLFQ-2.webp)

这会带来饥饿问题（starvation）。如果系统有“太多”交互型工作，就会不断占用
CPU，导致长工作永远无法得到 CPU（它们饿死了）。

这还会带来用户重写程序，愚弄调度程序。

## 8.3 尝试2：提升优先级

- 规则 5：经过一段时间 S，就将系统中所有工作重新加入最高优先级队列。

S如何设置是一个问题，。如果 S 设置得太高，长工作会饥饿；如果设置得太低，交互型工作又得不到合适的 CPU 时间比例。

![MLFQ-3](https://img.nobody404.xyz/img/MLFQ-3.webp)

## 8.4 尝试3：更好的计时方式

重写规则4a和4b

- 规则 4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级（移入低一级队列）。

![MLFQ-4](https://img.nobody404.xyz/img/MLFQ-4.webp)

## 8.5 MLFQ 调优及其他问题

主要是队列数量的配置数量和每层队列时间片配置等。

## 8.6 MLFQ：小结

MLFQ：它有多级队列，并利用反馈信息决定某个工作优先级。

# 第9章 调度：比例份额

这章我们学习比例份额调度程序。比例份额算法基于一个简单的想法：调度程序的最终目标，是确保每个工作获得一定比例的 CPU 时间，而不是优化周转时间和响应时间。

## 9.1 基本概念：彩票数表示份额

彩票数（ticket）代表了进程（或用户或其他）占有某个资源的份额。一个进程拥有的彩票数占总彩票数的百分比，就是它占有资源的份额。通过不断定时地（比如，每个时间片）抽取彩票，彩票调度从概率上（但不是确定的）获得这种份额比例。

## 9.2 彩票机制

1. 彩票货币
2. 彩票转让
3. 彩票通胀

## 9.3 实现

彩票调度的实现需要一个随机数生成器（选择彩票）和一个记录系统所有进程的数据结构，以及所有彩票总数。

## 9.4 一个例子

只有当工作执行非常多时间片的时，彩票调度算法才能得到期望的结果。

## 9.5 如何分配彩票

如何为用户分配彩票？这是一个非常棘手的问题，没有最佳答案。

## 9.6 为什么不是确定的

由于工作时间很短的情况下的不公平可能性大，所以Waldspurger提出了步长调度。

~~~
current = remove_min(queue);        // pick client with minimum pass 
schedule(current);                  // use resource for quantum 
current->pass += current->stride;   // compute next pass using stride 
insert(queue, current);             // put back into the queue 
~~~

彩票算法相较于步长协调算法的优势是不需要全局状态。

## 9.7 小结

上述2个算法都没得到广泛应用，原因有不适合I/O和票数分配。

结果，比例份额调度程序只有在这些问题可以相对容易解决的领域更有用（例如容易确定份额比例）。

# 第10章 多处理器调度（高级）

## 10.1 背景多处理器架构

为了理解多处理器调度带来的新问题，必须先知道它与单 CPU 之间的基本区别。区别的核心在于对硬件缓存（cache）的使用（见图 10.1），以及多处理器之间共享数据的方式。

缓存一致性问题

## 10.2 别忘了同步

跨 CPU 访问（尤其是写入）共享数据或数据结构时，需要使用互斥原语（比如锁），才能保证正确性（其他方法，如使用无锁（lock-free）数据结构，很复杂，偶尔才使用。详情参见并发部分关于死锁的章节）。

## 10.3 最后一个问题：缓存亲和度

一个进程在某个 CPU 上运行时，会在该 CPU 的缓存中维护许多状态。下次该进程在相同 CPU 上运行时，由于缓存中的数据而执行得更快。相反，在不同的 CPU 上执行，会由于需要重新加载数据而很慢

## 10.4 单队列调度（Single Queue Multiprocessor Scheduling，SQMS）

问题有缺乏可扩展性（scalability）和缓存亲和性。

## 10.4 多队列调度（Multi-Queue Multiprocessor Scheduling，MQMS）

MQMS 比 SQMS 有明显的优势，它天生更具有可扩展性。队列的数量会随着 CPU 的增加而增加，因此锁和缓存争用的开销不是大问题。

但是出现了新问题：负载不均（load imbalance），解决办法：让工作移动（migradtion）

## Linux 多处理器调度

见书91页

## 10.7 小结

本章介绍了多处理器调度的不同方法。他们各有优缺。